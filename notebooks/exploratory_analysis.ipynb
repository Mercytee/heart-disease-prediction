{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c136709",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Heart Disease Dataset - Exploratory Data Analysis\n",
    "# Team: Mercy Thokozani Ngwenya & Mediator Nhongo  \n",
    "# Date: 2025-10-27\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# 1. Setup and Data Loading\n",
    "\n",
    "# Load the dataset\n",
    "column_names = [\n",
    "    \"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\",\n",
    "    \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv('../data/cleveland.data', names=column_names, na_values='?', skipinitialspace=True)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "\n",
    "# 2. Basic Dataset Information\n",
    "\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Number of patients: {df.shape[0]}\")\n",
    "print(f\"Number of features: {df.shape[1]}\")\n",
    "print(f\"\\nColumn names: {list(df.columns)}\")\n",
    "\n",
    "print(\"\\n=== DATA TYPES ===\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n=== FIRST 5 ROWS ===\")\n",
    "print(df.head())\n",
    "\n",
    "# Missing values analysis\n",
    "print(\"=== MISSING VALUES ===\")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percentage': missing_percent\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "# 3. Target Variable Analysis\n",
    "\n",
    "df['target'] = df['num'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "print(\"=== TARGET VARIABLE DISTRIBUTION ===\")\n",
    "target_counts = df['target'].value_counts()\n",
    "target_percent = df['target'].value_counts(normalize=True) * 100\n",
    "\n",
    "target_summary = pd.DataFrame({\n",
    "    'Count': target_counts,\n",
    "    'Percentage': target_percent\n",
    "})\n",
    "print(target_summary)\n",
    "\n",
    "print(\"\\n=== ORIGINAL TARGET DISTRIBUTION (num) ===\")\n",
    "print(df['num'].value_counts().sort_index())\n",
    "\n",
    "# Visualize target distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "colors = ['lightcoral', 'lightblue']\n",
    "ax1.pie(target_counts.values, labels=['No Disease', 'Disease'], autopct='%1.1f%%', \n",
    "        colors=colors, startangle=90)\n",
    "ax1.set_title('Heart Disease Distribution (Binary)')\n",
    "\n",
    "original_counts = df['num'].value_counts().sort_index()\n",
    "ax2.bar(original_counts.index, original_counts.values, color='skyblue', alpha=0.7)\n",
    "ax2.set_xlabel('Heart Disease Severity (0-4)')\n",
    "ax2.set_ylabel('Number of Patients')\n",
    "ax2.set_title('Original Heart Disease Severity Distribution')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Feature Distributions\n",
    "\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    axes[i].hist(df[feature], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[i].set_title(f'Distribution of {feature}')\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "fig.delaxes(axes[5])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(categorical_features):\n",
    "    value_counts = df[feature].value_counts().sort_index()\n",
    "    axes[i].bar(value_counts.index.astype(str), value_counts.values, \n",
    "                color='lightgreen', alpha=0.7, edgecolor='black')\n",
    "    axes[i].set_title(f'Distribution of {feature}')\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('Count')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    for j, v in enumerate(value_counts.values):\n",
    "        axes[i].text(j, v + 1, str(v), ha='center', va='bottom')\n",
    "\n",
    "for i in range(len(categorical_features), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Statistical Summary\n",
    "\n",
    "print(\"=== NUMERICAL FEATURES STATISTICAL SUMMARY ===\")\n",
    "print(df[numerical_features].describe())\n",
    "\n",
    "print(\"=== CATEGORICAL FEATURES SUMMARY ===\")\n",
    "for feature in categorical_features:\n",
    "    print(f\"\\n{feature}:\")\n",
    "    print(df[feature].value_counts().sort_index())\n",
    "\n",
    "# 6. Correlation Analysis\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', \n",
    "            center=0, square=True, fmt='.2f',\n",
    "            cbar_kws={'shrink': 0.8})\n",
    "\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== TOP CORRELATIONS WITH TARGET ===\")\n",
    "target_correlations = correlation_matrix['target'].sort_values(ascending=False)\n",
    "target_correlations_df = pd.DataFrame({\n",
    "    'Feature': target_correlations.index,\n",
    "    'Correlation': target_correlations.values\n",
    "})\n",
    "print(target_correlations_df.head(10))\n",
    "\n",
    "# 7. Feature vs Target Analysis\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    data_to_plot = [df[df['target'] == 0][feature], df[df['target'] == 1][feature]]\n",
    "    axes[i].boxplot(data_to_plot, labels=['No Disease', 'Disease'])\n",
    "    axes[i].set_title(f'{feature} vs Heart Disease')\n",
    "    axes[i].set_ylabel(feature)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "fig.delaxes(axes[5])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(categorical_features):\n",
    "    cross_tab = pd.crosstab(df[feature], df['target'], normalize='index') * 100\n",
    "    cross_tab.plot(kind='bar', ax=axes[i], color=['lightcoral', 'lightblue'])\n",
    "    axes[i].set_title(f'{feature} vs Heart Disease')\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('Percentage (%)')\n",
    "    axes[i].legend(['No Disease', 'Disease'])\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "for i in range(len(categorical_features), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8. Missing Value Analysis\n",
    "\n",
    "print(\"=== DETAILED MISSING VALUE ANALYSIS ===\")\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Feature': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df)) * 100\n",
    "})\n",
    "\n",
    "missing_summary = missing_summary[missing_summary['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "if not missing_summary.empty:\n",
    "    print(missing_summary)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(missing_summary['Feature'], missing_summary['Missing_Percentage'], \n",
    "                   color='salmon', alpha=0.7, edgecolor='darkred')\n",
    "    plt.title('Missing Values Percentage by Feature', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Missing Percentage (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{height:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No missing values found in the dataset!\")\n",
    "\n",
    "# 9. Outlier Detection\n",
    "\n",
    "print(\"=== OUTLIER DETECTION (IQR METHOD) ===\")\n",
    "\n",
    "outlier_summary = []\n",
    "\n",
    "for feature in numerical_features:\n",
    "    Q1 = df[feature].quantile(0.25)\n",
    "    Q3 = df[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[feature] < lower_bound) | (df[feature] > upper_bound)]\n",
    "    outlier_count = len(outliers)\n",
    "    outlier_percentage = (outlier_count / len(df)) * 100\n",
    "    \n",
    "    outlier_summary.append({\n",
    "        'Feature': feature,\n",
    "        'Outlier_Count': outlier_count,\n",
    "        'Outlier_Percentage': outlier_percentage,\n",
    "        'Lower_Bound': lower_bound,\n",
    "        'Upper_Bound': upper_bound\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary)\n",
    "print(outlier_df)\n",
    "\n",
    "# 10. Key Insights and Conclusions\n",
    "\n",
    "print(\"=== KEY INSIGHTS ===\")\n",
    "print(f\"1. Dataset contains {df.shape[0]} patients and {df.shape[1]} features\")\n",
    "\n",
    "disease_percentage = (df['target'].sum() / len(df)) * 100\n",
    "print(f\"2. {disease_percentage:.1f}% of patients have heart disease\")\n",
    "\n",
    "total_missing = df.isnull().sum().sum()\n",
    "print(f\"3. Total missing values: {total_missing}\")\n",
    "\n",
    "top_corr_features = target_correlations.index[1:4]  # Skip target itself\n",
    "print(f\"4. Top features correlated with heart disease: {list(top_corr_features)}\")\n",
    "\n",
    "avg_age = df['age'].mean()\n",
    "print(f\"5. Average patient age: {avg_age:.1f} years\")\n",
    "\n",
    "male_percentage = (df['sex'].sum() / len(df)) * 100  # sex=1 is male\n",
    "print(f\"6. Male patients: {male_percentage:.1f}%\")\n",
    "\n",
    "# 11. Data Quality Assessment\n",
    "\n",
    "print(\"=== DATA QUALITY ASSESSMENT ===\")\n",
    "\n",
    "quality_metrics = {\n",
    "    'Metric': [\n",
    "        'Total Samples',\n",
    "        'Total Features', \n",
    "        'Missing Values Percentage',\n",
    "        'Duplicate Rows',\n",
    "        'Class Balance (Disease/No Disease)',\n",
    "        'Data Types Consistency',\n",
    "        'Outlier Percentage (Average)'\n",
    "    ],\n",
    "    'Value': [\n",
    "        f\"{len(df):,}\",\n",
    "        f\"{len(df.columns)}\",\n",
    "        f\"{(df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100:.2f}%\",\n",
    "        f\"{df.duplicated().sum()}\",\n",
    "        f\"{disease_percentage:.1f}% / {100-disease_percentage:.1f}%\",\n",
    "        \"Consistent\" if len(df.dtypes.unique()) <= 2 else \"Check Needed\",\n",
    "        f\"{outlier_df['Outlier_Percentage'].mean():.1f}%\"\n",
    "    ],\n",
    "    'Status': [\n",
    "        'âœ… Good' if len(df) > 100 else 'âš  Small',\n",
    "        'âœ… Good' if len(df.columns) >= 10 else 'âš  Limited',\n",
    "        'âœ… Good' if (df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100 < 5 else 'âš  High',\n",
    "        'âœ… Good' if df.duplicated().sum() == 0 else 'âš  Duplicates Found',\n",
    "        'âœ… Balanced' if 40 <= disease_percentage <= 60 else 'âš  Imbalanced',\n",
    "        'âœ… Good',\n",
    "        'âœ… Good' if outlier_df['Outlier_Percentage'].mean() < 10 else 'âš  High Outliers'\n",
    "    ]\n",
    "}\n",
    "\n",
    "quality_df = pd.DataFrame(quality_metrics)\n",
    "print(quality_df)\n",
    "\n",
    "# Summary\n",
    "print(\"\"\"\n",
    "---\n",
    "ðŸ“‹ Summary\n",
    "\n",
    "This exploratory analysis provides comprehensive insights into the Heart Disease dataset. Key findings include:\n",
    "\n",
    "- Dataset Quality: Good overall with minimal missing values\n",
    "- Class Distribution: Slightly imbalanced but manageable\n",
    "- Feature Relationships: Several strong correlations with target variable\n",
    "- Data Types: Appropriate for machine learning\n",
    "- Next Steps: Proceed with preprocessing and model development\n",
    "\n",
    "The dataset appears suitable for building predictive models for heart disease diagnosis.\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
