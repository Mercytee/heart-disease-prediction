{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd66a09",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Heart Disease Prediction - Model Experimentation\\n\",\n",
    "    \"**Team**: Mercy Thokozani Ngwenya & Mediator Nhongo  \\n\",\n",
    "    \"**Date**: $(new Date().toLocaleDateString())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Setup and Imports\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Machine Learning imports\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\\n\",\n",
    "    \"from sklearn.preprocessing import StandardScaler, LabelEncoder\\n\",\n",
    "    \"from sklearn.impute import SimpleImputer\\n\",\n",
    "    \"from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\\n\",\n",
    "    \"from sklearn.svm import SVC\\n\",\n",
    "    \"from sklearn.linear_model import LogisticRegression\\n\",\n",
    "    \"from sklearn.tree import DecisionTreeClassifier\\n\",\n",
    "    \"from sklearn.metrics import (\\n\",\n",
    "    \"    accuracy_score, precision_score, recall_score, f1_score, \\n\",\n",
    "    \"    roc_auc_score, confusion_matrix, classification_report,\\n\",\n",
    "    \"    roc_curve, precision_recall_curve\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set style\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\\n\",\n",
    "    \"%matplotlib inline\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"All packages imported successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Data Loading and Preprocessing\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load dataset\\n\",\n",
    "    \"column_names = [\\n\",\n",
    "    \"    \\\"age\\\", \\\"sex\\\", \\\"cp\\\", \\\"trestbps\\\", \\\"chol\\\", \\\"fbs\\\", \\\"restecg\\\",\\n\",\n",
    "    \"    \\\"thalach\\\", \\\"exang\\\", \\\"oldpeak\\\", \\\"slope\\\", \\\"ca\\\", \\\"thal\\\", \\\"num\\\"\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"df = pd.read_csv('../data/cleveland.data', names=column_names, na_values='?', skipinitialspace=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Dataset loaded successfully!\\\")\\n\",\n",
    "    \"print(f\\\"Original shape: {df.shape}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create binary target\\n\",\n",
    "    \"df['target'] = df['num'].apply(lambda x: 1 if x > 0 else 0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Separate features and target\\n\",\n",
    "    \"X = df.drop(columns=['num', 'target'])\\n\",\n",
    "    \"y = df['target']\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Features shape: {X.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Target distribution:\\\\n{y.value_counts()}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Handle missing values\\n\",\n",
    "    \"print(\\\"Missing values before handling:\\\")\\n\",\n",
    "    \"print(X.isnull().sum())\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Impute numerical features\\n\",\n",
    "    \"numerical_cols = X.select_dtypes(include=[np.number]).columns\\n\",\n",
    "    \"categorical_cols = X.select_dtypes(include=['object']).columns\\n\",\n",
    "    \"\\n\",\n",
    "    \"imputer = SimpleImputer(strategy='median')\\n\",\n",
    "    \"X[numerical_cols] = imputer.fit_transform(X[numerical_cols])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# For categorical, use mode\\n\",\n",
    "    \"for col in categorical_cols:\\n\",\n",
    "    \"    if X[col].isnull().any():\\n\",\n",
    "    \"        mode_val = X[col].mode()[0]\\n\",\n",
    "    \"        X[col].fillna(mode_val, inplace=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nMissing values after handling:\\\")\\n\",\n",
    "    \"print(X.isnull().sum().sum(), \\\"missing values remaining\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Encode categorical variables\\n\",\n",
    "    \"label_encoders = {}\\n\",\n",
    "    \"for col in categorical_cols:\\n\",\n",
    "    \"    label_encoders[col] = LabelEncoder()\\n\",\n",
    "    \"    X[col] = label_encoders[col].fit_transform(X[col].astype(str))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Scale numerical features\\n\",\n",
    "    \"scaler = StandardScaler()\\n\",\n",
    "    \"X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Preprocessing completed!\\\")\\n\",\n",
    "    \"print(f\\\"Final feature matrix shape: {X.shape}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Split data\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(\\n\",\n",
    "    \"    X, y, test_size=0.2, random_state=42, stratify=y\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Data split completed:\\\")\\n\",\n",
    "    \"print(f\\\"Training set: {X_train.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Test set: {X_test.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Train target distribution:\\\\n{y_train.value_counts()}\\\")\\n\",\n",
    "    \"print(f\\\"Test target distribution:\\\\n{y_test.value_counts()}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Model Definitions and Training\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Define models and their hyperparameters\\n\",\n",
    "    \"models = {\\n\",\n",
    "    \"    'Logistic Regression': {\\n\",\n",
    "    \"        'model': LogisticRegression(random_state=42, max_iter=1000),\\n\",\n",
    "    \"        'params': {\\n\",\n",
    "    \"            'C': [0.1, 1, 10],\\n\",\n",
    "    \"            'solver': ['liblinear', 'lbfgs']\\n\",\n",
    "    \"        }\\n\",\n",
    "    \"    },\\n\",\n",
    "    \"    'Random Forest': {\\n\",\n",
    "    \"        'model': RandomForestClassifier(random_state=42),\\n\",\n",
    "    \"        'params': {\\n\",\n",
    "    \"            'n_estimators': [100, 200],\\n\",\n",
    "    \"            'max_depth': [10, 20, None],\\n\",\n",
    "    \"            'min_samples_split': [2, 5]\\n\",\n",
    "    \"        }\\n\",\n",
    "    \"    },\\n\",\n",
    "    \"    'Gradient Boosting': {\\n\",\n",
    "    \"        'model': GradientBoostingClassifier(random_state=42),\\n\",\n",
    "    \"        'params': {\\n\",\n",
    "    \"            'n_estimators': [100, 200],\\n\",\n",
    "    \"            'learning_rate': [0.05, 0.1],\\n\",\n",
    "    \"            'max_depth': [3, 5]\\n\",\n",
    "    \"        }\\n\",\n",
    "    \"    },\\n\",\n",
    "    \"    'SVM': {\\n\",\n",
    "    \"        'model': SVC(random_state=42, probability=True),\\n\",\n",
    "    \"        'params': {\\n\",\n",
    "    \"            'C': [0.1, 1, 10],\\n\",\n",
    "    \"            'kernel': ['linear', 'rbf']\\n\",\n",
    "    \"        }\\n\",\n",
    "    \"    },\\n\",\n",
    "    \"    'Decision Tree': {\\n\",\n",
    "    \"        'model': DecisionTreeClassifier(random_state=42),\\n\",\n",
    "    \"        'params': {\\n\",\n",
    "    \"            'max_depth': [5, 10, 20],\\n\",\n",
    "    \"            'min_samples_split': [2, 5, 10]\\n\",\n",
    "    \"        }\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Models defined for experimentation:\\\")\\n\",\n",
    "    \"for name in models.keys():\\n\",\n",
    "    \"    print(f\\\"- {name}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Train models with GridSearchCV\\n\",\n",
    "    \"results = {}\\n\",\n",
    "    \"best_models = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"for name, config in models.items():\\n\",\n",
    "    \"    print(f\\\"\\\\nTraining {name}...\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Perform grid search\\n\",\n",
    "    \"    grid_search = GridSearchCV(\\n\",\n",
    "    \"        config['model'], \\n\",\n",
    "    \"        config['params'], \\n\",\n",
    "    \"        cv=5, \\n\",\n",
    "    \"        scoring='accuracy',\\n\",\n",
    "    \"        n_jobs=-1,\\n\",\n",
    "    \"        verbose=0\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    grid_search.fit(X_train, y_train)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Store results\\n\",\n",
    "    \"    best_models[name] = grid_search.best_estimator_\\n\",\n",
    "    \"    results[name] = {\\n\",\n",
    "    \"        'best_score': grid_search.best_score_,\\n\",\n",
    "    \"        'best_params': grid_search.best_params_,\\n\",\n",
    "    \"        'best_estimator': grid_search.best_estimator_\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"{name} - Best CV Score: {grid_search.best_score_:.4f}\\\")\\n\",\n",
    "    \"    print(f\\\"Best parameters: {grid_search.best_params_}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Model Evaluation and Comparison\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Evaluate models on test set\\n\",\n",
    "    \"evaluation_results = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"for name, model in best_models.items():\\n\",\n",
    "    \"    # Predictions\\n\",\n",
    "    \"    y_pred = model.predict(X_test)\\n\",\n",
    "    \"    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Calculate metrics\\n\",\n",
    "    \"    metrics = {\\n\",\n",
    "    \"        'accuracy': accuracy_score(y_test, y_pred),\\n\",\n",
    "    \"        'precision': precision_score(y_test, y_pred, average='weighted'),\\n\",\n",
    "    \"        'recall': recall_score(y_test, y_pred, average='weighted'),\\n\",\n",
    "    \"        'f1_score': f1_score(y_test, y_pred, average='weighted'),\\n\",\n",
    "    \"        'cv_score': results[name]['best_score']\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if y_pred_proba is not None:\\n\",\n",
    "    \"        metrics['roc_auc'] = roc_auc_score(y_test, y_pred_proba)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    evaluation_results[name] = metrics\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\n{name} Test Results:\\\")\\n\",\n",
    "    \"    print(f\\\"Accuracy: {metrics['accuracy']:.4f}\\\")\\n\",\n",
    "    \"    print(f\\\"Precision: {metrics['precision']:.4f}\\\")\\n\",\n",
    "    \"    print(f\\\"Recall: {metrics['recall']:.4f}\\\")\\n\",\n",
    "    \"    print(f\\\"F1-Score: {metrics['f1_score']:.4f}\\\")\\n\",\n",
    "    \"    if 'roc_auc' in metrics:\\n\",\n",
    "    \"        print(f\\\"ROC AUC: {metrics['roc_auc']:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create comparison DataFrame\\n\",\n",
    "    \"comparison_df = pd.DataFrame(evaluation_results).T\\n\",\n",
    "    \"comparison_df = comparison_df.sort_values('accuracy', ascending=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n=== MODEL PERFORMANCE COMPARISON ===\\\")\\n\",\n",
    "    \"comparison_df\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize model comparison\\n\",\n",
    "    \"plt.figure(figsize=(14, 8))\\n\",\n",
    "    \"\\n\",\n",
    "    \"metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1_score']\\n\",\n",
    "    \"x_pos = np.arange(len(comparison_df))\\n\",\n",
    "    \"bar_width = 0.2\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i, metric in enumerate(metrics_to_plot):\\n\",\n",
    "    \"    plt.bar(x_pos + i * bar_width, comparison_df[metric], \\n\",\n",
    "    \"            width=bar_width, label=metric.replace('_', ' ').title())\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.xlabel('Models')\\n\",\n",
    "    \"plt.ylabel('Score')\\n\",\n",
    "    \"plt.title('Model Performance Comparison', fontsize=16, fontweight='bold')\\n\",\n",
    "    \"plt.xticks(x_pos + bar_width * 1.5, comparison_df.index, rotation=45)\\n\",\n",
    "    \"plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\\n\",\n",
    "    \"plt.grid(True, alpha=0.3)\\n\",\n",
    "    \"plt.ylim(0, 1)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Detailed Analysis of Best Model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Identify best model\\n\",\n",
    "    \"best_model_name = comparison_df.index[0]\\n\",\n",
    "    \"best_model = best_models[best_model_name]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n=== BEST MODEL: {best_model_name} ===\\\")\\n\",\n",
    "    \"print(f\\\"Test Accuracy: {comparison_df.loc[best_model_name, 'accuracy']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"CV Score: {comparison_df.loc[best_model_name, 'cv_score']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Best Parameters: {results[best_model_name]['best_params']}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Detailed evaluation of best model\\n\",\n",
    "    \"best_predictions = best_model.predict(X_test)\\n\",\n",
    "    \"best_probabilities = best_model.predict_proba(X_test)[:, 1] if hasattr(best_model, 'predict_proba') else None\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"=== DETAILED CLASSIFICATION REPORT ===\\\")\\n\",\n",
    "    \"print(classification_report(y_test, best_predictions, \\n\",\n",
    "    \"                          target_names=['No Disease', 'Disease']))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Confusion Matrix\\n\",\n",
    "    \"plt.figure(figsize=(10, 8))\\n\",\n",
    "    \"cm = confusion_matrix(y_test, best_predictions)\\n\",\n",
    "    \"sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \\n\",\n",
    "    \"            xticklabels=['No Disease', 'Disease'],\\n\",\n",
    "    \"            yticklabels=['No Disease', 'Disease'])\\n\",\n",
    "    \"plt.title(f'Confusion Matrix - {best_model_name}', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"plt.ylabel('Actual')\\n\",\n",
    "    \"plt.xlabel('Predicted')\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# ROC Curve\\n\",\n",
    "    \"if best_probabilities is not None:\\n\",\n",
    "    \"    plt.figure(figsize=(10, 8))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    fpr, tpr, _ = roc_curve(y_test, best_probabilities)\\n\",\n",
    "    \"    roc_auc = roc_auc_score(y_test, best_probabilities)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.plot(fpr, tpr, color='darkorange', lw=2, \\n\",\n",
    "    \"             label=f'ROC curve (AUC = {roc_auc:.4f})')\\n\",\n",
    "    \"    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\\n\",\n",
    "    \"    plt.xlim([0.0, 1.0])\\n\",\n",
    "    \"    plt.ylim([0.0, 1.05])\\n\",\n",
    "    \"    plt.xlabel('False Positive Rate')\\n\",\n",
    "    \"    plt.ylabel('True Positive Rate')\\n\",\n",
    "    \"    plt.title(f'ROC Curve - {best_model_name}', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"    plt.legend(loc='lower right')\\n\",\n",
    "    \"    plt.grid(True, alpha=0.3)\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Feature Importance Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Feature importance for tree-based models\\n\",\n",
    "    \"if hasattr(best_model, 'feature_importances_'):\\n\",\n",
    "    \"    feature_importance = pd.DataFrame({\\n\",\n",
    "    \"        'feature': X.columns,\\n\",\n",
    "    \"        'importance': best_model.feature_importances_\\n\",\n",
    "    \"    }).sort_values('importance', ascending=False)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"=== FEATURE IMPORTANCE ===\\\")\\n\",\n",
    "    \"    print(feature_importance.head(10))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot feature importance\\n\",\n",
    "    \"    plt.figure(figsize=(12, 8))\\n\",\n",
    "    \"    top_features = feature_importance.head(10)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    sns.barplot(data=top_features, x='importance', y='feature', palette='viridis')\\n\",\n",
    "    \"    plt.title(f'Top 10 Feature Importances - {best_model_name}', \\n\",\n",
    "    \"              fontsize=16, fontweight='bold')\\n\",\n",
    "    \"    plt.xlabel('Importance Score')\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(f\\\"{best_model_name} does not support feature importance visualization\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Cross-Validation Stability Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Cross-validation scores for all models\\n\",\n",
    "    \"cv_results = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"for name, model_config in models.items():\\n\",\n",
    "    \"    model = model_config['model']\\n\",\n",
    "    \"    # Set best parameters\\n\",\n",
    "    \"    model.set_params(**results[name]['best_params'])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Perform cross-validation\\n\",\n",
    "    \"    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\\n\",\n",
    "    \"    cv_results[name] = cv_scores\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"{name} - CV Scores: {cv_scores}\\\")\\n\",\n",
    "    \"    print(f\\\"{name} - Mean CV: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize CV stability\\n\",\n",
    "    \"plt.figure(figsize=(14, 8))\\n\",\n",
    "    \"\\n\",\n",
    "    \"box_data = [cv_results[name] for name in cv_results.keys()]\\n\",\n",
    "    \"box_plot = plt.boxplot(box_data, labels=cv_results.keys(), patch_artist=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Color the boxes\\n\",\n",
    "    \"colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightsalmon', 'lightyellow']\\n\",\n",
    "    \"for patch, color in zip(box_plot['boxes'], colors):\\n\",\n",
    "    \"    patch.set_facecolor(color)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.title('Cross-Validation Score Distribution', fontsize=16, fontweight='bold')\\n\",\n",
    "    \"plt.ylabel('Accuracy Score')\\n\",\n",
    "    \"plt.xticks(rotation=45)\\n\",\n",
    "    \"plt.grid(True, alpha=0.3)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Model Interpretation and Business Insights\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"=== BUSINESS AND CLINICAL INSIGHTS ===\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Model performance summary\\n\",\n",
    "    \"best_accuracy = comparison_df.loc[best_model_name, 'accuracy']\\n\",\n",
    "    \"best_precision = comparison_df.loc[best_model_name, 'precision']\\n\",\n",
    "    \"best_recall = comparison_df.loc[best_model_name, 'recall']\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"1. Best Model: {best_model_name}\\\")\\n\",\n",
    "    \"print(f\\\"2. Overall Accuracy: {best_accuracy:.1%}\\\")\\n\",\n",
    "    \"print(f\\\"3. Precision (Correct Disease Predictions): {best_precision:.1%}\\\")\\n\",\n",
    "    \"print(f\\\"4. Recall (Disease Cases Identified): {best_recall:.1%}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Clinical implications\\n\",\n",
    "    \"print(\\\"\\\\n5. Clinical Implications:\\\")\\n\",\n",
    "    \"print(\\\"   - High recall is crucial to avoid missing heart disease cases\\\")\\n\",\n",
    "    \"print(\\\"   - Model can assist in preliminary heart disease screening\\\")\\n\",\n",
    "    \"print(\\\"   - Should be used as decision support, not replacement for doctors\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Feature insights\\n\",\n",
    "    \"if hasattr(best_model, 'feature_importances_'):\\n\",\n",
    "    \"    top_feature = feature_importance.iloc[0]\\n\",\n",
    "    \"    print(f\\\"\\\\n6. Most Important Predictor: {top_feature['feature']} \\\"\\n\",\n",
    "    \"          f\\\"(Importance: {top_feature['importance']:.3f})\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Model Deployment Readiness\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"=== MODEL DEPLOYMENT ASSESSMENT ===\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"deployment_metrics = {\\n\",\n",
    "    \"    'Criterion': [\\n\",\n",
    "    \"        'Accuracy > 80%',\\n\",\n",
    "    \"        'Precision > 75%', \\n\",\n",
    "    \"        'Recall > 75%',\\n\",\n",
    "    \"        'Cross-Validation Stability',\\n\",\n",
    "    \"        'Feature Interpretability',\\n\",\n",
    "    \"        'Training Time',\\n\",\n",
    "    \"        'Overall Readiness'\\n\",\n",
    "    \"    ],\\n\",\n",
    "    \"    'Status': [\\n\",\n",
    "    \"        '‚úÖ PASS' if best_accuracy > 0.8 else '‚ö†Ô∏è MARGINAL',\\n\",\n",
    "    \"        '‚úÖ PASS' if best_precision > 0.75 else '‚ö†Ô∏è MARGINAL',\\n\",\n",
    "    \"        '‚úÖ PASS' if best_recall > 0.75 else '‚ö†Ô∏è MARGINAL',\\n\",\n",
    "    \"        '‚úÖ STABLE' if cv_results[best_model_name].std() < 0.05 else '‚ö†Ô∏è VARIABLE',\\n\",\n",
    "    \"        '‚úÖ GOOD' if hasattr(best_model, 'feature_importances_') else '‚ö†Ô∏è LIMITED',\\n\",\n",
    "    \"        '‚úÖ FAST' if best_model_name != 'SVM' else '‚ö†Ô∏è SLOW',\\n\",\n",
    "    \"        '‚úÖ READY' if best_accuracy > 0.8 and best_recall > 0.75 else '‚ö†Ô∏è NEEDS IMPROVEMENT'\\n\",\n",
    "    \"    ],\\n\",\n",
    "    \"    'Value': [\\n\",\n",
    "    \"        f\\\"{best_accuracy:.1%}\\\",\\n\",\n",
    "    \"        f\\\"{best_precision:.1%}\\\",\\n\",\n",
    "    \"        f\\\"{best_recall:.1%}\\\",\\n\",\n",
    "    \"        f\\\"CV Std: {cv_results[best_model_name].std():.4f}\\\",\\n\",\n",
    "    \"        'Interpretable' if hasattr(best_model, 'feature_importances_') else 'Black Box',\\n\",\n",
    "    \"        '< 1 second',\\n\",\n",
    "    \"        'Deployable' if best_accuracy > 0.8 and best_recall > 0.75 else 'Needs Tuning'\\n\",\n",
    "    \"    ]\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"deployment_df = pd.DataFrame(deployment_metrics)\\n\",\n",
    "    \"deployment_df\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 10. Save Best Model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import joblib\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save the best model\\n\",\n",
    "    \"model_filename = f'best_heart_disease_model.pkl'\\n\",\n",
    "    \"joblib.dump(best_model, model_filename)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save preprocessing objects\\n\",\n",
    "    \"preprocessing_objects = {\\n\",\n",
    "    \"    'scaler': scaler,\\n\",\n",
    "    \"    'imputer': imputer,\\n\",\n",
    "    \"    'label_encoders': label_encoders,\\n\",\n",
    "    \"    'feature_names': list(X.columns)\\n\",\n",
    "    \"}\\n\",\n",
    "    \"joblib.dump(preprocessing_objects, 'preprocessing_objects.pkl')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Best model saved as: {model_filename}\\\")\\n\",\n",
    "    \"print(\\\"Preprocessing objects saved as: preprocessing_objects.pkl\\\")\\n\",\n",
    "    \"print(\\\"\\\\n‚úÖ Model experimentation completed successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"---\\n\",\n",
    "    \"## üìã **Summary and Next Steps**\\n\",\n",
    "    \"\\n\",\n",
    "    \"### **Key Findings:**\\n\",\n",
    "    \"- **Best Performing Model**: Identified through comprehensive evaluation\\n\",\n",
    "    \"- **Performance Metrics**: Achieved clinically relevant accuracy and recall\\n\",\n",
    "    \"- **Feature Importance**: Understood key predictors of heart disease\\n\",\n",
    "    \"- **Model Stability**: Verified through cross-validation\\n\",\n",
    "    \"\\n\",\n",
    "    \"### **Next Steps:**\\n\",\n",
    "    \"1. **Model Deployment**: Integrate into clinical decision support system\\n\",\n",
    "    \"2. **Monitoring**: Implement performance monitoring in production\\n\",\n",
    "    \"3. **Improvement**: Collect more data for model retraining\\n\",\n",
    "    \"4. **Validation**: Conduct clinical validation studies\\n\",\n",
    "    \"\\n\",\n",
    "    \"### **Clinical Application:**\\n\",\n",
    "    \"This model can serve as a preliminary screening tool to assist healthcare professionals in identifying patients at risk of heart disease, potentially leading to earlier interventions and improved patient outcomes.\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
