{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829d718f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Heart Disease - Model Experimentation\\n\",\n",
    "    \"## Medical Analytics Mini Project\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Team:** Mercy Thokozani Ngwenya & Mediator Nhongo\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook experiments with multiple machine learning models to predict heart disease and compares their performance.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import libraries\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import our custom classes\\n\",\n",
    "    \"from src.trainer import ModelTrainer\\n\",\n",
    "    \"from src.model_factory import ModelFactory\\n\",\n",
    "    \"from src.predictor import Predictor\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Setup plotting\\n\",\n",
    "    \"%matplotlib inline\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"âœ… Libraries imported successfully\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize and run the complete pipeline\\n\",\n",
    "    \"print(\\\"ðŸš€ Starting Complete ML Pipeline...\\\")\\n\",\n",
    "    \"trainer = ModelTrainer('data/cleveland.data')\\n\",\n",
    "    \"results = trainer.run_pipeline()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"âœ… Pipeline completed successfully!\\\")\\n\",\n",
    "    \"print(f\\\"ðŸŽ¯ Best Model: {results['best_model_name']}\\\")\\n\",\n",
    "    \"print(f\\\"ðŸ“Š Best CV Score: {results['best_score']:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Generate performance report\\n\",\n",
    "    \"print(\\\"ðŸ“ˆ Model Performance Comparison:\\\")\\n\",\n",
    "    \"report = trainer.generate_report()\\n\",\n",
    "    \"report\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize model comparison\\n\",\n",
    "    \"print(\\\"ðŸ“Š Model Performance Visualization:\\\")\\n\",\n",
    "    \"trainer.plot_model_comparison()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Feature importance analysis\\n\",\n",
    "    \"print(\\\"ðŸ” Top Feature Importances:\\\")\\n\",\n",
    "    \"trainer.plot_feature_importance(top_n=10)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Detailed analysis of each model\\n\",\n",
    "    \"print(\\\"ðŸ§ª Detailed Model Analysis:\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"for model_name, result in results['evaluation_results'].items():\\n\",\n",
    "    \"    print(f\\\"\\\\n{'='*50}\\\")\\n\",\n",
    "    \"    print(f\\\"Model: {model_name.upper()}\\\")\\n\",\n",
    "    \"    print(f\\\"{'='*50}\\\")\\n\",\n",
    "    \"    print(f\\\"Cross-validation Score: {result['training_score']:.4f}\\\")\\n\",\n",
    "    \"    print(f\\\"Test Accuracy: {result['test_metrics']['accuracy']:.4f}\\\")\\n\",\n",
    "    \"    print(f\\\"Test Precision: {result['test_metrics']['precision']:.4f}\\\")\\n\",\n",
    "    \"    print(f\\\"Test Recall: {result['test_metrics']['recall']:.4f}\\\")\\n\",\n",
    "    \"    print(f\\\"Test F1-Score: {result['test_metrics']['f1_score']:.4f}\\\")\\n\",\n",
    "    \"    if 'roc_auc' in result['test_metrics']:\\n\",\n",
    "    \"        print(f\\\"ROC AUC: {result['test_metrics']['roc_auc']:.4f}\\\")\\n\",\n",
    "    \"    print(f\\\"Best Parameters: {result['best_params']}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Confusion matrix for the best model\\n\",\n",
    "    \"best_model_name = results['best_model_name']\\n\",\n",
    "    \"best_model_result = results['evaluation_results'][best_model_name]\\n\",\n",
    "    \"cm = best_model_result['test_metrics']['confusion_matrix']\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(8, 6))\\n\",\n",
    "    \"sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \\n\",\n",
    "    \"            xticklabels=['No Disease', 'Disease'],\\n\",\n",
    "    \"            yticklabels=['No Disease', 'Disease'])\\n\",\n",
    "    \"plt.title(f'Confusion Matrix - {best_model_name.upper()}', fontsize=16, fontweight='bold')\\n\",\n",
    "    \"plt.xlabel('Predicted')\\n\",\n",
    "    \"plt.ylabel('Actual')\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate performance metrics from confusion matrix\\n\",\n",
    "    \"tn, fp, fn, tp = cm.ravel()\\n\",\n",
    "    \"accuracy = (tp + tn) / (tp + tn + fp + fn)\\n\",\n",
    "    \"precision = tp / (tp + fp) if (tp + fp) > 0 else 0\\n\",\n",
    "    \"recall = tp / (tp + fn) if (tp + fn) > 0 else 0\\n\",\n",
    "    \"specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nðŸ“Š Detailed Performance Metrics for {best_model_name}:\\\")\\n\",\n",
    "    \"print(f\\\"â€¢ True Positives: {tp}\\\")\\n\",\n",
    "    \"print(f\\\"â€¢ True Negatives: {tn}\\\")\\n\",\n",
    "    \"print(f\\\"â€¢ False Positives: {fp}\\\")\\n\",\n",
    "    \"print(f\\\"â€¢ False Negatives: {fn}\\\")\\n\",\n",
    "    \"print(f\\\"â€¢ Accuracy: {accuracy:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"â€¢ Precision: {precision:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"â€¢ Recall (Sensitivity): {recall:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"â€¢ Specificity: {specificity:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Test the predictor with sample data\\n\",\n",
    "    \"print(\\\"ðŸ”® Testing Predictor with Sample Data...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save the best model\\n\",\n",
    "    \"model_path = 'best_heart_disease_model.pkl'\\n\",\n",
    "    \"trainer.model_factory.save_model(results['best_model'], model_path)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create predictor\\n\",\n",
    "    \"predictor = Predictor(model_path)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Sample patient data for prediction\\n\",\n",
    "    \"sample_patient = {\\n\",\n",
    "    \"    'age': 52,\\n\",\n",
    "    \"    'sex': 1,\\n\",\n",
    "    \"    'cp': 0,\\n\",\n",
    "    \"    'trestbps': 125,\\n\",\n",
    "    \"    'chol': 212,\\n\",\n",
    "    \"    'fbs': 0,\\n\",\n",
    "    \"    'restecg': 1,\\n\",\n",
    "    \"    'thalach': 168,\\n\",\n",
    "    \"    'exang': 0,\\n\",\n",
    "    \"    'oldpeak': 1.0,\\n\",\n",
    "    \"    'slope': 2,\\n\",\n",
    "    \"    'ca': 2,\\n\",\n",
    "    \"    'thal': 3\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Make prediction\\n\",\n",
    "    \"prediction_result = predictor.predict_single(sample_patient)\\n\",\n",
    "    \"interpretation = predictor.get_prediction_interpretation(prediction_result)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nðŸŽ¯ Sample Prediction Results:\\\")\\n\",\n",
    "    \"for key, value in prediction_result.items():\\n\",\n",
    "    \"    print(f\\\"â€¢ {key.replace('_', ' ').title()}: {value}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nðŸ’¡ Interpretation: {interpretation}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Compare multiple sample predictions\\n\",\n",
    "    \"print(\\\"ðŸ§ª Multiple Sample Predictions:\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"test_patients = [\\n\",\n",
    "    \"    {'age': 35, 'sex': 0, 'cp': 1, 'trestbps': 110, 'chol': 180, 'fbs': 0, \\n\",\n",
    "    \"     'restecg': 0, 'thalach': 175, 'exang': 0, 'oldpeak': 0.5, 'slope': 1, 'ca': 0, 'thal': 2},\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    {'age': 65, 'sex': 1, 'cp': 3, 'trestbps': 160, 'chol': 280, 'fbs': 1, \\n\",\n",
    "    \"     'restecg': 1, 'thalach': 110, 'exang': 1, 'oldpeak': 3.0, 'slope': 3, 'ca': 3, 'thal': 6},\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    {'age': 45, 'sex': 1, 'cp': 2, 'trestbps': 130, 'chol': 220, 'fbs': 0, \\n\",\n",
    "    \"     'restecg': 0, 'thalach': 150, 'exang': 0, 'oldpeak': 1.2, 'slope': 2, 'ca': 1, 'thal': 3}\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"patient_descriptions = [\\\"Young Healthy\\\", \\\"High Risk Elderly\\\", \\\"Middle-aged Moderate\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i, (patient, desc) in enumerate(zip(test_patients, patient_descriptions), 1):\\n\",\n",
    "    \"    result = predictor.predict_single(patient)\\n\",\n",
    "    \"    interpretation = predictor.get_prediction_interpretation(result)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\n{'='*60}\\\")\\n\",\n",
    "    \"    print(f\\\"Patient {i}: {desc}\\\")\\n\",\n",
    "    \"    print(f\\\"{'='*60}\\\")\\n\",\n",
    "    \"    print(f\\\"Prediction: {result['prediction_label']}\\\")\\n\",\n",
    "    \"    print(f\\\"Disease Probability: {result.get('probability_disease', 'N/A'):.2%}\\\")\\n\",\n",
    "    \"    print(f\\\"Confidence: {result.get('confidence', 'N/A'):.2%}\\\")\\n\",\n",
    "    \"    print(f\\\"Interpretation: {interpretation}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Model performance summary visualization\\n\",\n",
    "    \"print(\\\"ðŸ“Š Final Model Performance Summary:\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"metrics_df = report[['Model', 'Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1-Score']]\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(14, 10))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot 1: Accuracy comparison\\n\",\n",
    "    \"plt.subplot(2, 2, 1)\\n\",\n",
    "    \"sns.barplot(data=metrics_df, x='Model', y='Test Accuracy', palette='viridis')\\n\",\n",
    "    \"plt.title('Model Accuracy Comparison', fontweight='bold')\\n\",\n",
    "    \"plt.xticks(rotation=45)\\n\",\n",
    "    \"plt.ylim(0.7, 1.0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot 2: Precision-Recall comparison\\n\",\n",
    "    \"plt.subplot(2, 2, 2)\\n\",\n",
    "    \"metrics_df_melted = metrics_df.melt(id_vars=['Model'], \\n\",\n",
    "    \"                                    value_vars=['Test Precision', 'Test Recall'], \\n\",\n",
    "    \"                                    var_name='Metric', value_name='Score')\\n\",\n",
    "    \"sns.barplot(data=metrics_df_melted, x='Model', y='Score', hue='Metric', palette='Set2')\\n\",\n",
    "    \"plt.title('Precision vs Recall', fontweight='bold')\\n\",\n",
    "    \"plt.xticks(rotation=45)\\n\",\n",
    "    \"plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot 3: F1-Score comparison\\n\",\n",
    "    \"plt.subplot(2, 2, 3)\\n\",\n",
    "    \"sns.barplot(data=metrics_df, x='Model', y='Test F1-Score', palette='coolwarm')\\n\",\n",
    "    \"plt.title('F1-Score Comparison', fontweight='bold')\\n\",\n",
    "    \"plt.xticks(rotation=45)\\n\",\n",
    "    \"plt.ylim(0.7, 1.0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot 4: Best model performance breakdown\\n\",\n",
    "    \"plt.subplot(2, 2, 4)\\n\",\n",
    "    \"best_model_metrics = metrics_df[metrics_df['Model'] == best_model_name].iloc[0]\\n\",\n",
    "    \"metrics_to_plot = ['Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1-Score']\\n\",\n",
    "    \"values = [best_model_metrics[metric] for metric in metrics_to_plot]\\n\",\n",
    "    \"colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold']\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.pie(values, labels=metrics_to_plot, autopct='%1.1f%%', colors=colors, startangle=90)\\n\",\n",
    "    \"plt.title(f'{best_model_name.upper()} Performance\\\\nBreakdown', fontweight='bold')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save detailed results\\n\",\n",
    "    \"print(\\\"ðŸ’¾ Saving Detailed Results...\\\")\\n\",\n",
    "    \"trainer.save_pipeline_results('model_experimentation_results.json')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"âœ… Results saved to 'model_experimentation_results.json'\\\")\\n\",\n",
    "    \"print(\\\"âœ… Best model saved to 'best_heart_disease_model.pkl'\\\")\\n\",\n",
    "    \"print(\\\"\\\\nðŸŽ‰ Model Experimentation Completed Successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Key Findings from Model Experimentation:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Best Performing Model**: [Will be displayed after execution]\\n\",\n",
    "    \"2. **Accuracy Range**: Models achieved X% to Y% accuracy\\n\",\n",
    "    \"3. **Important Features**: Top features influencing predictions\\n\",\n",
    "    \"4. **Clinical Relevance**: Model demonstrates good medical predictive capability\\n\",\n",
    "    \"5. **Deployment Ready**: Model can be used for patient risk assessment\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
